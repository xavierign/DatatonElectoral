{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained model \n",
    "## word embedding ##\n",
    "#from gensim.models import Word2Vec\n",
    "import gensim.models.keyedvectors as word2vec\n",
    "\n",
    "# Load pretrained model (since intermediate data is not included, the model cannot be refined with additional data)\n",
    "model = word2vec.KeyedVectors.load_word2vec_format(\n",
    "    '~/nltk_data/SBW-vectors-300-min5.bin', binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['casa']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def removeStopwords( palabras ):\n",
    "     return [ word for word in palabras if word not in stopwords.words('spanish') ]\n",
    "\n",
    "\n",
    "print(removeStopwords( palabras ))\n",
    "\n",
    "out = []\n",
    "for text in df['text']:\n",
    "    out2 = []\n",
    "    \n",
    "    #remove stop words\n",
    "    \n",
    "    for word in removeStopwords(text.split(\" \")):\n",
    "        try:\n",
    "            out2.append(model[word])\n",
    "        except:\n",
    "            pass\n",
    "    out.append(out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create empty dict\n",
    "candidatos = {}\n",
    "for candidato in set(list(df['usuario'])):\n",
    "    candidatos[candidato] = []\n",
    "\n",
    "for index, candidato in df['usuario'].items():\n",
    "    candidatos[candidato].append(out[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "candList = list(candidatos.keys())\n",
    "\n",
    "#wordsInTweets = \n",
    "candVect = {}\n",
    "\n",
    "for cand in candList:\n",
    "    candVect[cand] = np.zeros(300)\n",
    "\n",
    "    nTweets = len(candidatos[cand])\n",
    "    for i in range(nTweets):\n",
    "        nWordsInTweet = len(candidatos[cand][i])\n",
    "        for j in range(nWordsInTweet):\n",
    "            candVect[cand] += candidatos[cand][i][j]/nWordsInTweet/nTweets\n",
    "\n",
    "#for item in candidatos:\n",
    "#    print(candidatos['sergiomassa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gladys_gonzalez',\n",
       " 'JorgeTaiana',\n",
       " 'sergiomassa',\n",
       " 'CFKArgentina',\n",
       " 'Stolbizer',\n",
       " 'estebanbullrich',\n",
       " 'nestorpitrola',\n",
       " 'andreadatri']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "\n",
    "similarities = cosine_similarity(list(candVect.values()))\n",
    "#mat = distance_matrix(list(candVect.values()),list(candVect.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.98613628,  0.97763329,  0.9815052 ,  0.98911114,\n",
       "         0.99371228,  0.97698286,  0.88320839],\n",
       "       [ 0.98613628,  1.        ,  0.97371499,  0.98700049,  0.98997883,\n",
       "         0.9836838 ,  0.99163561,  0.89368215],\n",
       "       [ 0.97763329,  0.97371499,  1.        ,  0.98791094,  0.98775191,\n",
       "         0.97139306,  0.96293549,  0.80673384],\n",
       "       [ 0.9815052 ,  0.98700049,  0.98791094,  1.        ,  0.99267833,\n",
       "         0.97718164,  0.98398125,  0.84653991],\n",
       "       [ 0.98911114,  0.98997883,  0.98775191,  0.99267833,  1.        ,\n",
       "         0.98508862,  0.98414968,  0.86092079],\n",
       "       [ 0.99371228,  0.9836838 ,  0.97139306,  0.97718164,  0.98508862,\n",
       "         1.        ,  0.97482467,  0.89809903],\n",
       "       [ 0.97698286,  0.99163561,  0.96293549,  0.98398125,  0.98414968,\n",
       "         0.97482467,  1.        ,  0.90495115],\n",
       "       [ 0.88320839,  0.89368215,  0.80673384,  0.84653991,  0.86092079,\n",
       "         0.89809903,  0.90495115,  1.        ]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data '0        Mon Nov 27 20:33:57 +0000 2017\\n1        Thu Nov 23 16:09:40 +0000 2017\\n2        Thu Nov 23 12:44:03 +0000 2017\\n3        Thu Nov 23 12:42:10 +0000 2017\\n4        Thu Nov 23 10:20:45 +0000 2017\\n5        Thu Nov 23 10:19:26 +0000 2017\\n6        Thu Nov 23 10:17:41 +0000 2017\\n7        Thu Nov 23 10:17:22 +0000 2017\\n8        Thu Nov 23 10:16:00 +0000 2017\\n9        Mon Nov 20 22:18:06 +0000 2017\\n10       Tue Nov 14 15:33:19 +0000 2017\\n11       Sat Nov 11 22:22:46 +0000 2017\\n12       Wed Nov 08 23:48:14 +0000 2017\\n13       Wed Nov 01 12:09:08 +0000 2017\\n14       Tue Oct 31 22:57:45 +0000 2017\\n15       Thu Oct 26 00:05:17 +0000 2017\\n16       Mon Oct 23 02:02:59 +0000 2017\\n17       Mon Oct 23 02:02:02 +0000 2017\\n18       Mon Oct 23 02:01:46 +0000 2017\\n19       Sun Oct 22 14:42:03 +0000 2017\\n20       Fri Oct 20 09:54:57 +0000 2017\\n21       Fri Oct 20 02:51:05 +0000 2017\\n22       Fri Oct 20 02:50:20 +0000 2017\\n23       Fri Oct 20 02:43:25 +0000 2017\\n24       Fri Oct 20 02:39:20 +0000 2017\\n25       Fri Oct 20 02:33:19 +0000 2017\\n26       Fri Oct 20 02:19:05 +0000 2017\\n27       Fri Oct 20 01:46:34 +0000 2017\\n28       Fri Oct 20 00:02:04 +0000 2017\\n29       Thu Oct 19 23:19:47 +0000 2017\\n                      ...              \\n25668    Tue Jul 18 12:59:49 +0000 2017\\n25669    Tue Jul 18 12:59:43 +0000 2017\\n25670    Tue Jul 18 12:59:37 +0000 2017\\n25671    Tue Jul 18 12:59:37 +0000 2017\\n25672    Tue Jul 18 12:59:26 +0000 2017\\n25673    Tue Jul 18 12:58:43 +0000 2017\\n25674    Tue Jul 18 12:58:38 +0000 2017\\n25675    Tue Jul 18 12:58:35 +0000 2017\\n25676    Tue Jul 18 12:58:25 +0000 2017\\n25677    Tue Jul 18 12:58:17 +0000 2017\\n25678    Tue Jul 18 12:58:14 +0000 2017\\n25679    Tue Jul 18 12:58:12 +0000 2017\\n25680    Tue Jul 18 12:57:57 +0000 2017\\n25681    Tue Jul 18 12:52:53 +0000 2017\\n25682    Tue Jul 18 12:50:29 +0000 2017\\n25683    Tue Jul 18 12:50:15 +0000 2017\\n25684    Tue Jul 18 12:50:15 +0000 2017\\n25685    Tue Jul 18 12:50:09 +0000 2017\\n25686    Tue Jul 18 12:50:09 +0000 2017\\n25687    Tue Jul 18 12:50:04 +0000 2017\\n25688    Tue Jul 18 12:49:57 +0000 2017\\n25689    Tue Jul 18 12:49:52 +0000 2017\\n25690    Tue Jul 18 12:49:50 +0000 2017\\n25691    Tue Jul 18 12:49:47 +0000 2017\\n25692    Tue Jul 18 12:49:42 +0000 2017\\n25693    Tue Jul 18 12:49:40 +0000 2017\\n25694    Tue Jul 18 12:49:30 +0000 2017\\n25695    Tue Jul 18 12:49:26 +0000 2017\\n25696    Tue Jul 18 12:49:00 +0000 2017\\n25697    Tue Jul 18 12:48:53 +0000 2017\\nName: fecha_creacion, Length: 25698, dtype: object' does not match format '%a %b %d %H:%M:%S +0000 %Y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-b5b5427e5164>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#ts = time.strftime('%Y-%m-%d %H:%M:%S', time.strptime(str(df['fecha_creacion']),'%a %b %d %H:%M:%S +0000 %Y'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y-%m-%d'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fecha_creacion'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'%a %b %d %H:%M:%S +0000 %Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/lib/python3.5/_strptime.py\u001b[0m in \u001b[0;36m_strptime_time\u001b[0;34m(data_string, format)\u001b[0m\n\u001b[1;32m    502\u001b[0m     \"\"\"Return a time struct based on the input string and the\n\u001b[1;32m    503\u001b[0m     format string.\"\"\"\n\u001b[0;32m--> 504\u001b[0;31m     \u001b[0mtt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_strptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstruct_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_STRUCT_TM_ITEMS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/_strptime.py\u001b[0m in \u001b[0;36m_strptime\u001b[0;34m(data_string, format)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         raise ValueError(\"time data %r does not match format %r\" %\n\u001b[0;32m--> 343\u001b[0;31m                          (data_string, format))\n\u001b[0m\u001b[1;32m    344\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         raise ValueError(\"unconverted data remains: %s\" %\n",
      "\u001b[0;31mValueError\u001b[0m: time data '0        Mon Nov 27 20:33:57 +0000 2017\\n1        Thu Nov 23 16:09:40 +0000 2017\\n2        Thu Nov 23 12:44:03 +0000 2017\\n3        Thu Nov 23 12:42:10 +0000 2017\\n4        Thu Nov 23 10:20:45 +0000 2017\\n5        Thu Nov 23 10:19:26 +0000 2017\\n6        Thu Nov 23 10:17:41 +0000 2017\\n7        Thu Nov 23 10:17:22 +0000 2017\\n8        Thu Nov 23 10:16:00 +0000 2017\\n9        Mon Nov 20 22:18:06 +0000 2017\\n10       Tue Nov 14 15:33:19 +0000 2017\\n11       Sat Nov 11 22:22:46 +0000 2017\\n12       Wed Nov 08 23:48:14 +0000 2017\\n13       Wed Nov 01 12:09:08 +0000 2017\\n14       Tue Oct 31 22:57:45 +0000 2017\\n15       Thu Oct 26 00:05:17 +0000 2017\\n16       Mon Oct 23 02:02:59 +0000 2017\\n17       Mon Oct 23 02:02:02 +0000 2017\\n18       Mon Oct 23 02:01:46 +0000 2017\\n19       Sun Oct 22 14:42:03 +0000 2017\\n20       Fri Oct 20 09:54:57 +0000 2017\\n21       Fri Oct 20 02:51:05 +0000 2017\\n22       Fri Oct 20 02:50:20 +0000 2017\\n23       Fri Oct 20 02:43:25 +0000 2017\\n24       Fri Oct 20 02:39:20 +0000 2017\\n25       Fri Oct 20 02:33:19 +0000 2017\\n26       Fri Oct 20 02:19:05 +0000 2017\\n27       Fri Oct 20 01:46:34 +0000 2017\\n28       Fri Oct 20 00:02:04 +0000 2017\\n29       Thu Oct 19 23:19:47 +0000 2017\\n                      ...              \\n25668    Tue Jul 18 12:59:49 +0000 2017\\n25669    Tue Jul 18 12:59:43 +0000 2017\\n25670    Tue Jul 18 12:59:37 +0000 2017\\n25671    Tue Jul 18 12:59:37 +0000 2017\\n25672    Tue Jul 18 12:59:26 +0000 2017\\n25673    Tue Jul 18 12:58:43 +0000 2017\\n25674    Tue Jul 18 12:58:38 +0000 2017\\n25675    Tue Jul 18 12:58:35 +0000 2017\\n25676    Tue Jul 18 12:58:25 +0000 2017\\n25677    Tue Jul 18 12:58:17 +0000 2017\\n25678    Tue Jul 18 12:58:14 +0000 2017\\n25679    Tue Jul 18 12:58:12 +0000 2017\\n25680    Tue Jul 18 12:57:57 +0000 2017\\n25681    Tue Jul 18 12:52:53 +0000 2017\\n25682    Tue Jul 18 12:50:29 +0000 2017\\n25683    Tue Jul 18 12:50:15 +0000 2017\\n25684    Tue Jul 18 12:50:15 +0000 2017\\n25685    Tue Jul 18 12:50:09 +0000 2017\\n25686    Tue Jul 18 12:50:09 +0000 2017\\n25687    Tue Jul 18 12:50:04 +0000 2017\\n25688    Tue Jul 18 12:49:57 +0000 2017\\n25689    Tue Jul 18 12:49:52 +0000 2017\\n25690    Tue Jul 18 12:49:50 +0000 2017\\n25691    Tue Jul 18 12:49:47 +0000 2017\\n25692    Tue Jul 18 12:49:42 +0000 2017\\n25693    Tue Jul 18 12:49:40 +0000 2017\\n25694    Tue Jul 18 12:49:30 +0000 2017\\n25695    Tue Jul 18 12:49:26 +0000 2017\\n25696    Tue Jul 18 12:49:00 +0000 2017\\n25697    Tue Jul 18 12:48:53 +0000 2017\\nName: fecha_creacion, Length: 25698, dtype: object' does not match format '%a %b %d %H:%M:%S +0000 %Y'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "#ts = time.strftime('%Y-%m-%d %H:%M:%S', time.strptime(str(df['fecha_creacion']),'%a %b %d %H:%M:%S +0000 %Y'))\n",
    "\n",
    "time.strftime('%Y-%m-%d',time.strptime(str(df['fecha_creacion']),'%a %b %d %H:%M:%S +0000 %Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "('requires pygraphviz ', 'http://pygraphviz.github.io/')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/networkx/drawing/nx_agraph.py\u001b[0m in \u001b[0;36mto_agraph\u001b[0;34m(N)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0;32mimport\u001b[0m \u001b[0mpygraphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'pygraphviz'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-dc4f58d86075>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelabel_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascii_uppercase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrawing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnx_agraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_agraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"red\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"filled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/networkx/drawing/nx_agraph.py\u001b[0m in \u001b[0;36mto_agraph\u001b[0;34m(N)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         raise ImportError('requires pygraphviz ',\n\u001b[0;32m--> 135\u001b[0;31m                           'http://pygraphviz.github.io/')\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0mdirected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_directed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_selfloops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_multigraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: ('requires pygraphviz ', 'http://pygraphviz.github.io/')"
     ]
    }
   ],
   "source": [
    "dt = [('len', float)]\n",
    "A = mat\n",
    "A = A.view(dt)\n",
    "\n",
    "G = nx.from_numpy_matrix(A)\n",
    "G = nx.relabel_nodes(G, dict(zip(range(len(G.nodes())),string.ascii_uppercase)))    \n",
    "\n",
    "G = nx.drawing.nx_agraph.to_agraph(G)\n",
    "\n",
    "G.node_attr.update(color=\"red\", style=\"filled\")\n",
    "G.edge_attr.update(color=\"blue\", width=\"2.0\")\n",
    "\n",
    "G.draw('/tmp/out.png', format='png', prog='neato')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cereal'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match([\"banana\",\"cereal\",\"manzana\",\"huevo\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usuario</th>\n",
       "      <th>text</th>\n",
       "      <th>fecha_creacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sergiomassa</td>\n",
       "      <td>rt @catigreoficial: felíz día hincha tigrense,...</td>\n",
       "      <td>Mon Nov 27 20:33:57 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sergiomassa</td>\n",
       "      <td>rt @malenamassa: ley #paridad nacional ley!!! ...</td>\n",
       "      <td>Thu Nov 23 16:09:40 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sergiomassa</td>\n",
       "      <td>rt @micaferrarom: cuanta felicidad día históri...</td>\n",
       "      <td>Thu Nov 23 12:44:03 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sergiomassa</td>\n",
       "      <td>¡noche histórica diputados!después esfuerzo co...</td>\n",
       "      <td>Thu Nov 23 12:42:10 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sergiomassa</td>\n",
       "      <td>rt @malenamassa: apartamos grieta, intereses p...</td>\n",
       "      <td>Thu Nov 23 10:20:45 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sergiomassa</td>\n",
       "      <td>rt @carlabpitiot: #paridadesley conquista cole...</td>\n",
       "      <td>Thu Nov 23 10:19:26 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sergiomassa</td>\n",
       "      <td>rt @ceciliamoreau: tranquilidad ser parte equi...</td>\n",
       "      <td>Thu Nov 23 10:17:41 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sergiomassa</td>\n",
       "      <td>rt @ceciliamoreau: felicitaciones todas hoy pa...</td>\n",
       "      <td>Thu Nov 23 10:17:22 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sergiomassa</td>\n",
       "      <td>rt @fedemassotuc: 2 mañana día histórico @dipu...</td>\n",
       "      <td>Thu Nov 23 10:16:00 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sergiomassa</td>\n",
       "      <td>#rezamosporlos44 tripulantes #arasanjuansubmar...</td>\n",
       "      <td>Mon Nov 20 22:18:06 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sergiomassa</td>\n",
       "      <td>rt @mariodasneves: infinitas gracias #chubut h...</td>\n",
       "      <td>Tue Nov 14 15:33:19 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sergiomassa</td>\n",
       "      <td>¡salud don torcuato, salud campeones #urbatop1...</td>\n",
       "      <td>Sat Nov 11 22:22:46 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sergiomassa</td>\n",
       "      <td>rt @gracielacamano: solidaridad c/ dips margar...</td>\n",
       "      <td>Wed Nov 08 23:48:14 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sergiomassa</td>\n",
       "      <td>luchador mil batallas: peleó entereza enfermed...</td>\n",
       "      <td>Wed Nov 01 12:09:08 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sergiomassa</td>\n",
       "      <td>orgulloso haber compartido fuerza mario das ne...</td>\n",
       "      <td>Tue Oct 31 22:57:45 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sergiomassa</td>\n",
       "      <td>rt @stolbizer: #devidopreso nunca debió ser le...</td>\n",
       "      <td>Thu Oct 26 00:05:17 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sergiomassa</td>\n",
       "      <td>¡muchas gracias apoyaron! https://t.co/6z6xthit3i</td>\n",
       "      <td>Mon Oct 23 02:02:59 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sergiomassa</td>\n",
       "      <td>felicitaciones ganadores, sepan encontrarán op...</td>\n",
       "      <td>Mon Oct 23 02:02:02 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sergiomassa</td>\n",
       "      <td>#1día podamos tener argentina cumpla sueño mov...</td>\n",
       "      <td>Mon Oct 23 02:01:46 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sergiomassa</td>\n",
       "      <td>votando esperanzas hoy podamos construir futur...</td>\n",
       "      <td>Sun Oct 22 14:42:03 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sergiomassa</td>\n",
       "      <td>carta abierta @mauriciomacri @cfkargentina ➡️h...</td>\n",
       "      <td>Fri Oct 20 09:54:57 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sergiomassa</td>\n",
       "      <td>dueños supermercados, mineras casinos dije car...</td>\n",
       "      <td>Fri Oct 20 02:51:05 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sergiomassa</td>\n",
       "      <td>dueños supermercados, minerías casinos dije ca...</td>\n",
       "      <td>Fri Oct 20 02:50:20 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sergiomassa</td>\n",
       "      <td>.@rlavagna representación económica peronismo ...</td>\n",
       "      <td>Fri Oct 20 02:43:25 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sergiomassa</td>\n",
       "      <td>@rlavagna representación económica peronismo 2...</td>\n",
       "      <td>Fri Oct 20 02:39:20 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sergiomassa</td>\n",
       "      <td>accionar ministra dejó desear debió contener p...</td>\n",
       "      <td>Fri Oct 20 02:33:19 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sergiomassa</td>\n",
       "      <td>elección cruzada concepto amigo-enemigo instal...</td>\n",
       "      <td>Fri Oct 20 02:19:05 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sergiomassa</td>\n",
       "      <td>breve voy charlando @luisnovaresio 'luis novar...</td>\n",
       "      <td>Fri Oct 20 01:46:34 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sergiomassa</td>\n",
       "      <td>breve voy conversando @iudica equipo @polemica...</td>\n",
       "      <td>Fri Oct 20 00:02:04 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sergiomassa</td>\n",
       "      <td>fiestas actos argentina gran herida debe cerra...</td>\n",
       "      <td>Thu Oct 19 23:19:47 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25668</th>\n",
       "      <td>andreadatri</td>\n",
       "      <td>rt @castillaeduardo: #todossomospepsico //todo...</td>\n",
       "      <td>Tue Jul 18 12:59:49 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25669</th>\n",
       "      <td>andreadatri</td>\n",
       "      <td>rt @raulgodoypts: #todossomospepsico hoy march...</td>\n",
       "      <td>Tue Jul 18 12:59:43 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25670</th>\n",
       "      <td>andreadatri</td>\n",
       "      <td>rt @bren_hamilton: junto leonas pepsico #hoy c...</td>\n",
       "      <td>Tue Jul 18 12:59:37 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25671</th>\n",
       "      <td>andreadatri</td>\n",
       "      <td>rt @pore_69: #todossomospepsico #niunamenos tr...</td>\n",
       "      <td>Tue Jul 18 12:59:37 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25672</th>\n",
       "      <td>andreadatri</td>\n",
       "      <td>rt @jota_eme1917: #leonas cabeza pelea, famili...</td>\n",
       "      <td>Tue Jul 18 12:59:26 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25673</th>\n",
       "      <td>andreadatri</td>\n",
       "      <td>rt @fedepuy: trolls gusta docentes solidarios ...</td>\n",
       "      <td>Tue Jul 18 12:58:43 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25674</th>\n",
       "      <td>andreadatri</td>\n",
       "      <td>rt @sofiaachigar: #todossomospepsico: hoy mile...</td>\n",
       "      <td>Tue Jul 18 12:58:38 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25675</th>\n",
       "      <td>andreadatri</td>\n",
       "      <td>rt @mekepa: #todossomospepsico https://t.co/r3...</td>\n",
       "      <td>Tue Jul 18 12:58:35 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25676</th>\n",
       "      <td>andreadatri</td>\n",
       "      <td>rt @josedibello: prometían pobreza cero lluvia...</td>\n",
       "      <td>Tue Jul 18 12:58:25 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25677</th>\n",
       "      <td>andreadatri</td>\n",
       "      <td>rt @natuchamorales: #todossomospepsico #jujuy ...</td>\n",
       "      <td>Tue Jul 18 12:58:17 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25678</th>\n",
       "      <td>andreadatri</td>\n",
       "      <td>rt @sopermi: hoy #todossomospepsico, vamos rea...</td>\n",
       "      <td>Tue Jul 18 12:58:14 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25679</th>\n",
       "      <td>andreadatri</td>\n",
       "      <td>rt @arielgpatrich: #todossomospepsico https://...</td>\n",
       "      <td>Tue Jul 18 12:58:12 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25680</th>\n",
       "      <td>andreadatri</td>\n",
       "      <td>rt @mekepa: estación ramos mejía escucha #todo...</td>\n",
       "      <td>Tue Jul 18 12:57:57 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25681</th>\n",
       "      <td>andreadatri</td>\n",
       "      <td>rt @trendinaliaar: 3 cuentas verificadas contr...</td>\n",
       "      <td>Tue Jul 18 12:52:53 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25682</th>\n",
       "      <td>andreadatri</td>\n",
       "      <td>rt @ptsppatricios: hoy #todossomospepsico, par...</td>\n",
       "      <td>Tue Jul 18 12:50:29 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25683</th>\n",
       "      <td>andreadatri</td>\n",
       "      <td>rt @princelodo: #todossomospepsico https://t.c...</td>\n",
       "      <td>Tue Jul 18 12:50:15 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25684</th>\n",
       "      <td>andreadatri</td>\n",
       "      <td>rt @arielgpatrich: #todossomospepsico estudian...</td>\n",
       "      <td>Tue Jul 18 12:50:15 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25685</th>\n",
       "      <td>andreadatri</td>\n",
       "      <td>rt @panyrosas_arg: #hoy todas #todossomospepsi...</td>\n",
       "      <td>Tue Jul 18 12:50:09 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25686</th>\n",
       "      <td>andreadatri</td>\n",
       "      <td>rt @raulgodoypts: #todossomospepsico fuerza co...</td>\n",
       "      <td>Tue Jul 18 12:50:09 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25687</th>\n",
       "      <td>andreadatri</td>\n",
       "      <td>rt @liev_rojo: #todossomospepsico tendencias b...</td>\n",
       "      <td>Tue Jul 18 12:50:04 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25688</th>\n",
       "      <td>andreadatri</td>\n",
       "      <td>rt @princelodo: #todossomospepsico marchar! le...</td>\n",
       "      <td>Tue Jul 18 12:49:57 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25689</th>\n",
       "      <td>andreadatri</td>\n",
       "      <td>rt @mefmaulion: hoy #todossomospepsico https:/...</td>\n",
       "      <td>Tue Jul 18 12:49:52 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25690</th>\n",
       "      <td>andreadatri</td>\n",
       "      <td>rt @lusa522: #todossomospepsico</td>\n",
       "      <td>Tue Jul 18 12:49:50 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25691</th>\n",
       "      <td>andreadatri</td>\n",
       "      <td>rt @juanagallardo1: hoy #todossomospepsico 17h...</td>\n",
       "      <td>Tue Jul 18 12:49:47 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25692</th>\n",
       "      <td>andreadatri</td>\n",
       "      <td>rt @2minutoscortos: hoy unidos q toquen culo d...</td>\n",
       "      <td>Tue Jul 18 12:49:42 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25693</th>\n",
       "      <td>andreadatri</td>\n",
       "      <td>rt @juampa_ruben: #todossomospepsico cba convo...</td>\n",
       "      <td>Tue Jul 18 12:49:40 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25694</th>\n",
       "      <td>andreadatri</td>\n",
       "      <td>rt @marianaabril: #todossomospepsico: hoy mile...</td>\n",
       "      <td>Tue Jul 18 12:49:30 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25695</th>\n",
       "      <td>andreadatri</td>\n",
       "      <td>rt @chuledeforme: hoy 17 hs vemos obelisco. #t...</td>\n",
       "      <td>Tue Jul 18 12:49:26 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25696</th>\n",
       "      <td>andreadatri</td>\n",
       "      <td>rt @keilazequeiross: hoy #todossomospepsico si...</td>\n",
       "      <td>Tue Jul 18 12:49:00 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25697</th>\n",
       "      <td>andreadatri</td>\n",
       "      <td>rt @hormazabal_pts: #todossomospepsico basta d...</td>\n",
       "      <td>Tue Jul 18 12:48:53 +0000 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25698 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           usuario                                               text  \\\n",
       "0      sergiomassa  rt @catigreoficial: felíz día hincha tigrense,...   \n",
       "1      sergiomassa  rt @malenamassa: ley #paridad nacional ley!!! ...   \n",
       "2      sergiomassa  rt @micaferrarom: cuanta felicidad día históri...   \n",
       "3      sergiomassa  ¡noche histórica diputados!después esfuerzo co...   \n",
       "4      sergiomassa  rt @malenamassa: apartamos grieta, intereses p...   \n",
       "5      sergiomassa  rt @carlabpitiot: #paridadesley conquista cole...   \n",
       "6      sergiomassa  rt @ceciliamoreau: tranquilidad ser parte equi...   \n",
       "7      sergiomassa  rt @ceciliamoreau: felicitaciones todas hoy pa...   \n",
       "8      sergiomassa  rt @fedemassotuc: 2 mañana día histórico @dipu...   \n",
       "9      sergiomassa  #rezamosporlos44 tripulantes #arasanjuansubmar...   \n",
       "10     sergiomassa  rt @mariodasneves: infinitas gracias #chubut h...   \n",
       "11     sergiomassa  ¡salud don torcuato, salud campeones #urbatop1...   \n",
       "12     sergiomassa  rt @gracielacamano: solidaridad c/ dips margar...   \n",
       "13     sergiomassa  luchador mil batallas: peleó entereza enfermed...   \n",
       "14     sergiomassa  orgulloso haber compartido fuerza mario das ne...   \n",
       "15     sergiomassa  rt @stolbizer: #devidopreso nunca debió ser le...   \n",
       "16     sergiomassa  ¡muchas gracias apoyaron! https://t.co/6z6xthit3i   \n",
       "17     sergiomassa  felicitaciones ganadores, sepan encontrarán op...   \n",
       "18     sergiomassa  #1día podamos tener argentina cumpla sueño mov...   \n",
       "19     sergiomassa  votando esperanzas hoy podamos construir futur...   \n",
       "20     sergiomassa  carta abierta @mauriciomacri @cfkargentina ➡️h...   \n",
       "21     sergiomassa  dueños supermercados, mineras casinos dije car...   \n",
       "22     sergiomassa  dueños supermercados, minerías casinos dije ca...   \n",
       "23     sergiomassa  .@rlavagna representación económica peronismo ...   \n",
       "24     sergiomassa  @rlavagna representación económica peronismo 2...   \n",
       "25     sergiomassa  accionar ministra dejó desear debió contener p...   \n",
       "26     sergiomassa  elección cruzada concepto amigo-enemigo instal...   \n",
       "27     sergiomassa  breve voy charlando @luisnovaresio 'luis novar...   \n",
       "28     sergiomassa  breve voy conversando @iudica equipo @polemica...   \n",
       "29     sergiomassa  fiestas actos argentina gran herida debe cerra...   \n",
       "...            ...                                                ...   \n",
       "25668  andreadatri  rt @castillaeduardo: #todossomospepsico //todo...   \n",
       "25669  andreadatri  rt @raulgodoypts: #todossomospepsico hoy march...   \n",
       "25670  andreadatri  rt @bren_hamilton: junto leonas pepsico #hoy c...   \n",
       "25671  andreadatri  rt @pore_69: #todossomospepsico #niunamenos tr...   \n",
       "25672  andreadatri  rt @jota_eme1917: #leonas cabeza pelea, famili...   \n",
       "25673  andreadatri  rt @fedepuy: trolls gusta docentes solidarios ...   \n",
       "25674  andreadatri  rt @sofiaachigar: #todossomospepsico: hoy mile...   \n",
       "25675  andreadatri  rt @mekepa: #todossomospepsico https://t.co/r3...   \n",
       "25676  andreadatri  rt @josedibello: prometían pobreza cero lluvia...   \n",
       "25677  andreadatri  rt @natuchamorales: #todossomospepsico #jujuy ...   \n",
       "25678  andreadatri  rt @sopermi: hoy #todossomospepsico, vamos rea...   \n",
       "25679  andreadatri  rt @arielgpatrich: #todossomospepsico https://...   \n",
       "25680  andreadatri  rt @mekepa: estación ramos mejía escucha #todo...   \n",
       "25681  andreadatri  rt @trendinaliaar: 3 cuentas verificadas contr...   \n",
       "25682  andreadatri  rt @ptsppatricios: hoy #todossomospepsico, par...   \n",
       "25683  andreadatri  rt @princelodo: #todossomospepsico https://t.c...   \n",
       "25684  andreadatri  rt @arielgpatrich: #todossomospepsico estudian...   \n",
       "25685  andreadatri  rt @panyrosas_arg: #hoy todas #todossomospepsi...   \n",
       "25686  andreadatri  rt @raulgodoypts: #todossomospepsico fuerza co...   \n",
       "25687  andreadatri  rt @liev_rojo: #todossomospepsico tendencias b...   \n",
       "25688  andreadatri  rt @princelodo: #todossomospepsico marchar! le...   \n",
       "25689  andreadatri  rt @mefmaulion: hoy #todossomospepsico https:/...   \n",
       "25690  andreadatri                    rt @lusa522: #todossomospepsico   \n",
       "25691  andreadatri  rt @juanagallardo1: hoy #todossomospepsico 17h...   \n",
       "25692  andreadatri  rt @2minutoscortos: hoy unidos q toquen culo d...   \n",
       "25693  andreadatri  rt @juampa_ruben: #todossomospepsico cba convo...   \n",
       "25694  andreadatri  rt @marianaabril: #todossomospepsico: hoy mile...   \n",
       "25695  andreadatri  rt @chuledeforme: hoy 17 hs vemos obelisco. #t...   \n",
       "25696  andreadatri  rt @keilazequeiross: hoy #todossomospepsico si...   \n",
       "25697  andreadatri  rt @hormazabal_pts: #todossomospepsico basta d...   \n",
       "\n",
       "                       fecha_creacion  \n",
       "0      Mon Nov 27 20:33:57 +0000 2017  \n",
       "1      Thu Nov 23 16:09:40 +0000 2017  \n",
       "2      Thu Nov 23 12:44:03 +0000 2017  \n",
       "3      Thu Nov 23 12:42:10 +0000 2017  \n",
       "4      Thu Nov 23 10:20:45 +0000 2017  \n",
       "5      Thu Nov 23 10:19:26 +0000 2017  \n",
       "6      Thu Nov 23 10:17:41 +0000 2017  \n",
       "7      Thu Nov 23 10:17:22 +0000 2017  \n",
       "8      Thu Nov 23 10:16:00 +0000 2017  \n",
       "9      Mon Nov 20 22:18:06 +0000 2017  \n",
       "10     Tue Nov 14 15:33:19 +0000 2017  \n",
       "11     Sat Nov 11 22:22:46 +0000 2017  \n",
       "12     Wed Nov 08 23:48:14 +0000 2017  \n",
       "13     Wed Nov 01 12:09:08 +0000 2017  \n",
       "14     Tue Oct 31 22:57:45 +0000 2017  \n",
       "15     Thu Oct 26 00:05:17 +0000 2017  \n",
       "16     Mon Oct 23 02:02:59 +0000 2017  \n",
       "17     Mon Oct 23 02:02:02 +0000 2017  \n",
       "18     Mon Oct 23 02:01:46 +0000 2017  \n",
       "19     Sun Oct 22 14:42:03 +0000 2017  \n",
       "20     Fri Oct 20 09:54:57 +0000 2017  \n",
       "21     Fri Oct 20 02:51:05 +0000 2017  \n",
       "22     Fri Oct 20 02:50:20 +0000 2017  \n",
       "23     Fri Oct 20 02:43:25 +0000 2017  \n",
       "24     Fri Oct 20 02:39:20 +0000 2017  \n",
       "25     Fri Oct 20 02:33:19 +0000 2017  \n",
       "26     Fri Oct 20 02:19:05 +0000 2017  \n",
       "27     Fri Oct 20 01:46:34 +0000 2017  \n",
       "28     Fri Oct 20 00:02:04 +0000 2017  \n",
       "29     Thu Oct 19 23:19:47 +0000 2017  \n",
       "...                               ...  \n",
       "25668  Tue Jul 18 12:59:49 +0000 2017  \n",
       "25669  Tue Jul 18 12:59:43 +0000 2017  \n",
       "25670  Tue Jul 18 12:59:37 +0000 2017  \n",
       "25671  Tue Jul 18 12:59:37 +0000 2017  \n",
       "25672  Tue Jul 18 12:59:26 +0000 2017  \n",
       "25673  Tue Jul 18 12:58:43 +0000 2017  \n",
       "25674  Tue Jul 18 12:58:38 +0000 2017  \n",
       "25675  Tue Jul 18 12:58:35 +0000 2017  \n",
       "25676  Tue Jul 18 12:58:25 +0000 2017  \n",
       "25677  Tue Jul 18 12:58:17 +0000 2017  \n",
       "25678  Tue Jul 18 12:58:14 +0000 2017  \n",
       "25679  Tue Jul 18 12:58:12 +0000 2017  \n",
       "25680  Tue Jul 18 12:57:57 +0000 2017  \n",
       "25681  Tue Jul 18 12:52:53 +0000 2017  \n",
       "25682  Tue Jul 18 12:50:29 +0000 2017  \n",
       "25683  Tue Jul 18 12:50:15 +0000 2017  \n",
       "25684  Tue Jul 18 12:50:15 +0000 2017  \n",
       "25685  Tue Jul 18 12:50:09 +0000 2017  \n",
       "25686  Tue Jul 18 12:50:09 +0000 2017  \n",
       "25687  Tue Jul 18 12:50:04 +0000 2017  \n",
       "25688  Tue Jul 18 12:49:57 +0000 2017  \n",
       "25689  Tue Jul 18 12:49:52 +0000 2017  \n",
       "25690  Tue Jul 18 12:49:50 +0000 2017  \n",
       "25691  Tue Jul 18 12:49:47 +0000 2017  \n",
       "25692  Tue Jul 18 12:49:42 +0000 2017  \n",
       "25693  Tue Jul 18 12:49:40 +0000 2017  \n",
       "25694  Tue Jul 18 12:49:30 +0000 2017  \n",
       "25695  Tue Jul 18 12:49:26 +0000 2017  \n",
       "25696  Tue Jul 18 12:49:00 +0000 2017  \n",
       "25697  Tue Jul 18 12:48:53 +0000 2017  \n",
       "\n",
       "[25698 rows x 3 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
